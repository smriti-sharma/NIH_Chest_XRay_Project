{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"checkWithAllRules.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"qmfEAokQTRMI","colab_type":"code","outputId":"0657194e-8aba-4398-ce65-c3089cd58d50","executionInfo":{"status":"ok","timestamp":1589821639490,"user_tz":-330,"elapsed":21802,"user":{"displayName":"Ekta Vaishali Smriti MajorProject","photoUrl":"","userId":"17997308963185169646"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZdgnCIfyTIgi","colab_type":"code","outputId":"a2414631-cc86-4c43-a8f4-8c4c650ebf6c","executionInfo":{"status":"ok","timestamp":1589821644570,"user_tz":-330,"elapsed":1939,"user":{"displayName":"Ekta Vaishali Smriti MajorProject","photoUrl":"","userId":"17997308963185169646"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import pandas as pd\n","#car = pd.read_csv(\"/content/gdrive/My Drive/FCA/rulesconfbased.csv\",index_col=0)\n","#car = pd.read_csv(\"/content/gdrive/My Drive/FCA/Data Files/AllRules_30k/confBasedRules.csv\",index_col=0)\n","\n","\n","car = pd.read_csv(\"/content/gdrive/My Drive/FCA/Data Files/FinalData1/trans1_confBasedRules.csv\")\n","\n","print(len(car))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["39109\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6WTLMfnGG_y_","colab_type":"code","outputId":"8e2ee23a-7f25-4aaa-d23e-784736225216","executionInfo":{"status":"ok","timestamp":1589804438745,"user_tz":-330,"elapsed":1090,"user":{"displayName":"Ekta Vaishali Smriti MajorProject","photoUrl":"","userId":"17997308963185169646"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["print(car.loc[car.index[7], 'premise'])\n","car.head()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["{Correlation, Homogeneity}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>premise</th>\n","      <th>consequence</th>\n","      <th>support</th>\n","      <th>confidence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>{Correlation}</td>\n","      <td>{No Finding}</td>\n","      <td>0.53</td>\n","      <td>0.53</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>{Homogeneity}</td>\n","      <td>{No Finding}</td>\n","      <td>0.24</td>\n","      <td>0.53</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>{Inverse Difference Moment}</td>\n","      <td>{No Finding}</td>\n","      <td>0.24</td>\n","      <td>0.53</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>{Difference Entropy}</td>\n","      <td>{No Finding}</td>\n","      <td>0.40</td>\n","      <td>0.54</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>{Sum Averange}</td>\n","      <td>{No Finding}</td>\n","      <td>0.18</td>\n","      <td>0.59</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                      premise   consequence  support  confidence\n","0           0                {Correlation}  {No Finding}     0.53        0.53\n","1           1                {Homogeneity}  {No Finding}     0.24        0.53\n","2           2  {Inverse Difference Moment}  {No Finding}     0.24        0.53\n","3           3         {Difference Entropy}  {No Finding}     0.40        0.54\n","4           4               {Sum Averange}  {No Finding}     0.18        0.59"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"2rQ3AIUnz8ed","colab_type":"code","colab":{}},"source":["def sorter(df):\n","  len_lhs=[]\n","  \n","  for i in df.index:\n","      p = df.at[i, 'premise']\n","      if isinstance(p, str):\n","        p = p.replace('{', '')\n","        p = p.replace('}', '')\n","        p = set(p.split(', '))\n","        df['premise'][i] = p\n","      \n","      c = set(df.at[i, \"consequence\"])\n","      if isinstance(c, str):\n","        c = c.replace('{', '')\n","        c = c.replace('}', '')\n","        c = set(c.split(', '))\n","        df['consequence'][i] = c\n","      \n","      len_lhs.append(len(list(p)))\n","\n","  df['LengthLHS'] = len_lhs\n","  df.sort_values(by=['confidence'], ascending=False, inplace=True)\n","  return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XMvELy-8z_f5","colab_type":"code","outputId":"d3de925a-9601-47c6-9dd8-76e78cc09404","executionInfo":{"status":"ok","timestamp":1589821665190,"user_tz":-330,"elapsed":14502,"user":{"displayName":"Ekta Vaishali Smriti MajorProject","photoUrl":"","userId":"17997308963185169646"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["car = sorter(car)\n","car.head()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  # Remove the CWD from sys.path while we load stuff.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>premise</th>\n","      <th>consequence</th>\n","      <th>support</th>\n","      <th>confidence</th>\n","      <th>LengthLHS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>26685</th>\n","      <td>76062</td>\n","      <td>{Difference Entropy, Cluster Prominence, Entro...</td>\n","      <td>{Effusion}</td>\n","      <td>0.0</td>\n","      <td>0.95</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>15595</th>\n","      <td>50815</td>\n","      <td>{Difference Entropy, Cluster Prominence, Dissi...</td>\n","      <td>{Effusion}</td>\n","      <td>0.0</td>\n","      <td>0.95</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>35021</th>\n","      <td>92849</td>\n","      <td>{Difference Entropy, Cluster Prominence, Dissi...</td>\n","      <td>{Effusion}</td>\n","      <td>0.0</td>\n","      <td>0.94</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>26645</th>\n","      <td>75925</td>\n","      <td>{Sum Entropy, Difference Entropy, Cluster Prom...</td>\n","      <td>{Effusion}</td>\n","      <td>0.0</td>\n","      <td>0.94</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>31085</th>\n","      <td>85674</td>\n","      <td>{Mass, Nodule, Entropy, Consolidation, Atelect...</td>\n","      <td>{Effusion}</td>\n","      <td>0.0</td>\n","      <td>0.93</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Unnamed: 0  ... LengthLHS\n","26685       76062  ...         6\n","15595       50815  ...         6\n","35021       92849  ...         7\n","26645       75925  ...         7\n","31085       85674  ...         6\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"IGSC3jrAwNlu","colab_type":"code","colab":{}},"source":["#Compute and return jaccard similarity index between premise and instance\n","\n","def jaccard_sim(premise, instance):\n","    j = len(premise.intersection(instance))/len(premise.union(instance))\n","    return j"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MeJjNzJswQJA","colab_type":"code","colab":{}},"source":["def check_df(df, feature_set, labels):\n","  jaccardvalues = {}\n","  \n","  for i in df.index:\n","    premise = df.at[i, 'premise']\n","    feat_prem = set()\n","\n","    for el in premise:\n","      if not(el in labels):\n","        feat_prem.add(el)\n","\n","    if not(feat_prem == set()) and feat_prem.issubset(feature_set):\n","      jac = jaccard_sim(feat_prem, feature_set)\n","      jaccardvalues.update({i:jac})\n","  return jaccardvalues"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DyyGdIumwhxn","colab_type":"code","colab":{}},"source":["import numpy as np\n","from sklearn.metrics import roc_auc_score\n","import operator\n","\n","def test_jaccard(X, Y, feat_list, labels):  \n","    \n","    predictions = []\n","    ctr = 0\n","    count = 0\n","    \n","    for a in range(len(X)):\n","      pred = [0]*len(labels)\n","      feature_set = set()\n","      for j in range(16):\n","          #16: n_features\n","          if X[a][j] == 1:\n","              feature_set.add(str(feat_list[j]))\n","\n","      jaccards = check_df(car, feature_set, labels)\n","      jaccards = dict(sorted(jaccards.items(), key=operator.itemgetter(1),reverse=True))  #sort the dictionary in descending order\n","      #print(jaccards)\n","\n","      no_of_values = 51\n","      top_pairs = {k: jaccards[k] for k in list(jaccards)[:no_of_values]}\n","      #print(top_pairs)\n","       \n","      cons = []\n","      for key in top_pairs.keys():\n","        con = car.at[key, 'consequence'] \n","        cons.append(con)                #create a list of top 21 consequences \n","\n","      counts = dict()\n","      for i in cons:\n","        counts[i] = counts.get(i, 0) + 1\n","      #print(cons)\n","      #print(counts)\n","\n","      if bool(counts):\n","        max_cons = max(counts, key=counts.get) #find the consequence with the maximum count\n","      #print(max_cons)\n","\n","        if isinstance(max_cons, str):\n","          con = con.replace('{','')\n","          con = con.replace('}','')\n","          con = set(con.split(', '))\n","        for c in con:\n","          pred[labels.index(c)] = 1\n","\n","      else:\n","        ctr = ctr + 1\n","        #print(\"No match for instance \", a+1)\n","        #pred[labels.index('No Finding')] = 1\n","\n","      predictions.append(pred)\n","      if pred == list(Y[a]):\n","        count += 1\n","\n","    print('Correctly classified = ', count)\n","    predictions = np.array(predictions)\n","\n","    flag = False\n","    try:\n","      auc = roc_auc_score(Y, predictions, average=None)\n","      flag = True\n","    except ValueError:\n","      pass\n","    if(flag):\n","      tempdf = pd.DataFrame()\n","      tempdf['label'] = labels\n","      tempdf['AUC'] = auc\n","      print(\"Class-wise auc : \\n\", tempdf)\n","\n","    predictions = predictions.flatten()\n","    Y = Y.flatten()\n","    auc_t = roc_auc_score(Y,predictions,average=\"weighted\")\n","    print(\"Combined auc : \" ,auc_t)\n","    print(\"No match found:\" , ctr)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vrBzkw61xdJE","colab_type":"code","outputId":"561b8257-19a4-411f-a35a-57dfe4d85a63","executionInfo":{"status":"ok","timestamp":1589821678200,"user_tz":-330,"elapsed":1460,"user":{"displayName":"Ekta Vaishali Smriti MajorProject","photoUrl":"","userId":"17997308963185169646"}},"colab":{"base_uri":"https://localhost:8080/","height":258}},"source":["# data_frame = pd.read_csv(\"/content/gdrive/My Drive/FCA/Data Files/FinalData1/test.csv\", index_col=0)\n","data = pd.read_csv(\"/content/gdrive/My Drive/FCA/Data Files/FinalData1/test.csv\")\n","# data = data_frame.sample(200)\n","data.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image Index</th>\n","      <th>Finding Labels</th>\n","      <th>Contrast</th>\n","      <th>Homogeneity</th>\n","      <th>Energy</th>\n","      <th>Correlation</th>\n","      <th>Dissimilarity</th>\n","      <th>ASM</th>\n","      <th>Inverse Difference Moment</th>\n","      <th>Variance</th>\n","      <th>Sum Averange</th>\n","      <th>Sum Entropy</th>\n","      <th>Difference Entropy</th>\n","      <th>Inertia</th>\n","      <th>Cluster Shade</th>\n","      <th>Cluster Prominence</th>\n","      <th>Entropy</th>\n","      <th>Maximum Probability</th>\n","      <th>Mass</th>\n","      <th>No Finding</th>\n","      <th>Nodule</th>\n","      <th>Pneumothorax</th>\n","      <th>Infiltration</th>\n","      <th>Emphysema</th>\n","      <th>Edema</th>\n","      <th>Consolidation</th>\n","      <th>Hernia</th>\n","      <th>Pneumonia</th>\n","      <th>Cardiomegaly</th>\n","      <th>Pleural_Thickening</th>\n","      <th>Fibrosis</th>\n","      <th>Atelectasis</th>\n","      <th>Effusion</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00000001_002.png</td>\n","      <td>Cardiomegaly|Effusion</td>\n","      <td>13.064677</td>\n","      <td>0.564775</td>\n","      <td>0.042099</td>\n","      <td>0.998599</td>\n","      <td>1.386116</td>\n","      <td>0.001772</td>\n","      <td>0.564775</td>\n","      <td>13.064677</td>\n","      <td>334.268845</td>\n","      <td>9.117170</td>\n","      <td>0.006431</td>\n","      <td>13.064677</td>\n","      <td>-2.344133e+06</td>\n","      <td>1.008983e+09</td>\n","      <td>7.088873</td>\n","      <td>0.011783</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00000002_000.png</td>\n","      <td>No Finding</td>\n","      <td>6.499827</td>\n","      <td>0.464725</td>\n","      <td>0.035710</td>\n","      <td>0.998582</td>\n","      <td>1.673413</td>\n","      <td>0.001275</td>\n","      <td>0.464725</td>\n","      <td>6.499827</td>\n","      <td>360.245327</td>\n","      <td>8.752106</td>\n","      <td>0.007640</td>\n","      <td>6.499827</td>\n","      <td>-8.073136e+05</td>\n","      <td>2.850427e+08</td>\n","      <td>7.205706</td>\n","      <td>0.005526</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00000003_007.png</td>\n","      <td>Hernia</td>\n","      <td>23.132369</td>\n","      <td>0.355550</td>\n","      <td>0.025374</td>\n","      <td>0.997666</td>\n","      <td>2.598154</td>\n","      <td>0.000644</td>\n","      <td>0.355550</td>\n","      <td>23.132369</td>\n","      <td>265.734624</td>\n","      <td>9.474674</td>\n","      <td>0.010240</td>\n","      <td>23.132369</td>\n","      <td>-7.144502e+05</td>\n","      <td>6.973201e+08</td>\n","      <td>7.954700</td>\n","      <td>0.013064</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00000005_000.png</td>\n","      <td>No Finding</td>\n","      <td>28.039577</td>\n","      <td>0.558369</td>\n","      <td>0.039719</td>\n","      <td>0.996309</td>\n","      <td>1.495486</td>\n","      <td>0.001578</td>\n","      <td>0.558369</td>\n","      <td>28.039577</td>\n","      <td>340.519673</td>\n","      <td>9.149473</td>\n","      <td>0.006894</td>\n","      <td>28.039577</td>\n","      <td>-1.608152e+06</td>\n","      <td>7.056162e+08</td>\n","      <td>7.110231</td>\n","      <td>0.014586</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00000005_001.png</td>\n","      <td>No Finding</td>\n","      <td>40.673566</td>\n","      <td>0.610719</td>\n","      <td>0.052758</td>\n","      <td>0.991237</td>\n","      <td>1.342741</td>\n","      <td>0.002783</td>\n","      <td>0.610719</td>\n","      <td>40.673566</td>\n","      <td>325.354141</td>\n","      <td>8.347984</td>\n","      <td>0.005798</td>\n","      <td>40.673566</td>\n","      <td>-1.506846e+06</td>\n","      <td>4.677392e+08</td>\n","      <td>6.552632</td>\n","      <td>0.009903</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Image Index         Finding Labels  ...  Atelectasis  Effusion\n","0  00000001_002.png  Cardiomegaly|Effusion  ...          0.0       1.0\n","1  00000002_000.png             No Finding  ...          0.0       0.0\n","2  00000003_007.png                 Hernia  ...          0.0       0.0\n","3  00000005_000.png             No Finding  ...          0.0       0.0\n","4  00000005_001.png             No Finding  ...          0.0       0.0\n","\n","[5 rows x 33 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"S0io-wd7xhyY","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import KBinsDiscretizer\n","import numpy as np\n","\n","kdis = KBinsDiscretizer(n_bins = 2, encode = \"ordinal\", strategy = \"kmeans\")\n","\n","for c in data.columns[2:18]:\n","    c_dash = []\n","    temp = np.reshape(np.array(data[c]), (-1,1))\n","    c_dash = kdis.fit_transform(temp)\n","    data[c] = c_dash"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NusZNDbwxmPY","colab_type":"code","colab":{}},"source":["X = data.values[:, 2:18].astype(int)\n","Y = data.values[:, 18:33].astype(int)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Au8JqNvmxrU4","colab_type":"code","colab":{}},"source":["feature_names = data.columns[2:18]\n","label_names = data.columns[18:33]\n","features = []\n","\n","#removing space from between the feature names, because thats how they are in rules\n","for item in feature_names:\n","    it = item.replace(\" \",\"\")\n","    features.append(it)\n","\n","test_jaccard(X, Y, list(features), list(label_names))"],"execution_count":0,"outputs":[]}]}